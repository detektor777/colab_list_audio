{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOj/nYSma3e60WWplw/VAO2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/detektor777/colab_list_audio/blob/main/fishaudio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ArkdSOC_0biQ"
      },
      "outputs": [],
      "source": [
        "#@title ##**Install** { display-mode: \"form\" }\n",
        "%%capture\n",
        "!apt-get update\n",
        "!apt-get install -y libsox-dev ffmpeg\n",
        "\n",
        "!pip install huggingface_hub\n",
        "!git clone https://github.com/fishaudio/fish-speech.git\n",
        "!pip install -e /content/fish-speech[stable]\n",
        "!pip install tiktoken lightning pyrootutils loralib vector_quantize_pytorch loguru hydra-core\n",
        "!huggingface-cli download fishaudio/fish-speech-1.5 --local-dir /content/checkpoints/fish-speech-1.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Run** { display-mode: \"form\" }\n",
        "import os\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "project_root = \"/content/fish-speech\"\n",
        "checkpoint_path = \"/content/checkpoints/fish-speech-1.5\"\n",
        "decoder_checkpoint_path = \"/content/checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n",
        "output_dir = \"/content/output\"\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "os.environ['PYTHONPATH'] = f\"{project_root}{os.pathsep}{os.environ.get('PYTHONPATH', '')}\"\n",
        "text = 'hello world' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "!python -m fish_speech.models.text2semantic.inference \\\n",
        "    --text \"$text\" \\\n",
        "    --checkpoint-path \"$checkpoint_path\" \\\n",
        "    --output-dir \"$output_dir\"\n",
        "\n",
        "codes_file = os.path.join(output_dir, \"codes_0.npy\")\n",
        "\n",
        "output_audio = os.path.join(output_dir, \"fake.wav\")\n",
        "!python -m fish_speech.models.vqgan.inference \\\n",
        "    -i \"$codes_file\" \\\n",
        "    --checkpoint-path \"$decoder_checkpoint_path\" \\\n",
        "    --output-path \"$output_audio\"\n",
        "\n",
        "if os.path.exists(output_audio):\n",
        "    display(Audio(filename=output_audio))\n",
        "else:\n",
        "    print(f\"File {output_audio} was not generated. Check errors above.\")\n"
      ],
      "metadata": {
        "id": "mxGXrgqL0kaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clone voice**"
      ],
      "metadata": {
        "id": "cBSU9C464Lpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Upload Audio** { display-mode: \"form\" }\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "os.makedirs('/content/audio', exist_ok=True)\n",
        "\n",
        "for filename, content in uploaded.items():\n",
        "    with open(f'/content/audio/{filename}', 'wb') as f:\n",
        "        f.write(content)\n",
        "    audio_filename = filename\n",
        "\n",
        "print(f\"Audio file {audio_filename} successfully uploaded to /content/audio/\")\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "decoder_checkpoint_path = \"/content/checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n",
        "temp_folder = \"/content/temp_audio_folder\"\n",
        "\n",
        "if 'audio_filename' not in globals():\n",
        "    print(\"Error: First, execute the audio upload cell!\")\n",
        "else:\n",
        "    audio_path = f\"/content/audio/{audio_filename}\"\n",
        "    npy_filename = os.path.splitext(audio_filename)[0] + \".npy\"\n",
        "    prompt_tokens = f\"/content/audio/{npy_filename}\"\n",
        "\n",
        "    if not os.path.exists(audio_path):\n",
        "        print(f\"Error: File {audio_path} not found. Please re-upload the audio.\")\n",
        "    else:\n",
        "        os.makedirs(temp_folder, exist_ok=True)\n",
        "        shutil.copy(audio_path, temp_folder)\n",
        "\n",
        "        !python /content/fish-speech/tools/vqgan/extract_vq.py \\\n",
        "            \"$temp_folder\" \\\n",
        "            --num-workers 1 \\\n",
        "            --batch-size 16 \\\n",
        "            --config-name \"firefly_gan_vq\" \\\n",
        "            --checkpoint-path \"$decoder_checkpoint_path\"\n",
        "\n",
        "        generated_npy = f\"{temp_folder}/{os.path.splitext(audio_filename)[0]}.npy\"\n",
        "        if os.path.exists(generated_npy):\n",
        "            shutil.move(generated_npy, prompt_tokens)\n",
        "            print(f\"Tokens successfully saved to {prompt_tokens}\")\n",
        "        else:\n",
        "            print(f\"Error: File {prompt_tokens} was not created. Check the command output.\")\n",
        "\n",
        "        shutil.rmtree(temp_folder)\n"
      ],
      "metadata": {
        "id": "1atLk0bu0xD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Generate Audio from Text** { display-mode: \"form\" }\n",
        "import os\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "checkpoint_path = \"/content/checkpoints/fish-speech-1.5\"\n",
        "decoder_checkpoint_path = \"/content/checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n",
        "output_dir = \"/content/output\"\n",
        "\n",
        "prompt_text = 'hello world' #@param {type:\"string\"}\n",
        "\n",
        "if 'prompt_tokens' not in globals():\n",
        "    print(\"Error: First, execute the voice cloning cell!\")\n",
        "else:\n",
        "    if not os.path.exists(prompt_tokens):\n",
        "        print(f\"Error: File {prompt_tokens} not found. Please perform voice cloning.\")\n",
        "    else:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        !python -m fish_speech.models.text2semantic.inference \\\n",
        "            --text \"$prompt_text\" \\\n",
        "            --prompt-text \"$prompt_text\" \\\n",
        "            --prompt-tokens \"$prompt_tokens\" \\\n",
        "            --checkpoint-path \"$checkpoint_path\" \\\n",
        "            --output-dir \"$output_dir\" \\\n",
        "            --num-samples 1 2>/dev/null\n",
        "\n",
        "        codes_file = os.path.join(output_dir, \"codes_0.npy\")\n",
        "        output_audio = os.path.join(output_dir, \"fake.wav\")\n",
        "\n",
        "        !python -m fish_speech.models.vqgan.inference \\\n",
        "            -i \"$codes_file\" \\\n",
        "            --checkpoint-path \"$decoder_checkpoint_path\" \\\n",
        "            --output-path \"$output_audio\" 2>/dev/null\n",
        "\n",
        "        if os.path.exists(output_audio):\n",
        "            print(\"Generation completed! Here is your audio:\")\n",
        "            display(Audio(filename=output_audio))\n",
        "        else:\n",
        "            print(f\"Error: File {output_audio} was not generated.\")"
      ],
      "metadata": {
        "id": "LjCPwr_Y6gUh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}