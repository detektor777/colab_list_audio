{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiH+zV2nwHmzJ36xm5z1KK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/detektor777/colab_list_audio/blob/main/whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3PN2bsdXI5h"
      },
      "outputs": [],
      "source": [
        "#@title ##**Install** { display-mode: \"form\" }\n",
        "%%capture\n",
        "\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q git+https://github.com/yt-dlp/yt-dlp.git\n",
        "!pip install -q ipywidgets\n",
        "\n",
        "!pip install -q torch torchaudio\n",
        "!pip install -q moviepy\n",
        "\n",
        "import IPython\n",
        "IPython.display.clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Select Audio File** { display-mode: \"form\" }\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "upload_option = \"Upload from PC\"  #@param [\"Upload from PC\", \"Load from Google Drive Root\", \"Load from Google Drive\"]\n",
        "\n",
        "audio_file_path = None\n",
        "\n",
        "def convert_to_wav(input_file, output_file):\n",
        "    print(f\"Converting {input_file} to WAV...\")\n",
        "    video_formats = ['.mp4', '.mkv', '.avi', '.mov']\n",
        "    if os.path.splitext(input_file)[1].lower() in video_formats:\n",
        "        audio = AudioSegment.from_file(input_file)\n",
        "        audio.export(output_file, format=\"wav\")\n",
        "        print(f\"Converted to {output_file}\")\n",
        "        return output_file\n",
        "    return input_file\n",
        "\n",
        "if upload_option == \"Upload from PC\":\n",
        "    print(\"Please upload an audio or video file.\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        file_name = list(uploaded.keys())[0]\n",
        "        audio_file_path = file_name\n",
        "        if not audio_file_path.endswith('.wav'):\n",
        "            audio_file_path = convert_to_wav(file_name, \"converted_audio.wav\")\n",
        "    else:\n",
        "        print(\"No file uploaded.\")\n",
        "        audio_file_path = None\n",
        "\n",
        "elif upload_option == \"Load from Google Drive Root\":\n",
        "    drive.mount('/content/drive')\n",
        "    root_dir = '/content/drive/MyDrive/'\n",
        "\n",
        "    audio_video_extensions = ['.mp3', '.wav', '.flac', '.aac', '.mp4', '.mkv', '.avi', '.mov']\n",
        "    files_list = []\n",
        "\n",
        "    # Рекурсивный обход всех папок в Google Drive\n",
        "    for dirpath, _, filenames in os.walk(root_dir):\n",
        "        for f in filenames:\n",
        "            if os.path.splitext(f)[1].lower() in audio_video_extensions:\n",
        "                relative_path = os.path.relpath(os.path.join(dirpath, f), root_dir)\n",
        "                files_list.append(relative_path)\n",
        "\n",
        "    if not files_list:\n",
        "        print(\"No audio or video files found in Google Drive or its subfolders.\")\n",
        "        audio_file_path = None\n",
        "    else:\n",
        "        print(\"Select a file from Google Drive (including subfolders):\")\n",
        "\n",
        "        output = widgets.Output()\n",
        "        buttons = []\n",
        "\n",
        "        def on_button_clicked(b):\n",
        "            global audio_file_path\n",
        "            with output:\n",
        "                clear_output()\n",
        "                selected_file = b.description\n",
        "                full_path = os.path.join(root_dir, selected_file)\n",
        "                if os.path.splitext(selected_file)[1].lower() in ['.mp4', '.mkv', '.avi', '.mov']:\n",
        "                    audio_file_path = convert_to_wav(full_path, \"/content/converted_audio.wav\")\n",
        "                else:\n",
        "                    audio_file_path = full_path\n",
        "                print(f\"Selected file: {audio_file_path}\")\n",
        "\n",
        "        for file in files_list:\n",
        "            button = widgets.Button(description=file)\n",
        "            button.on_click(on_button_clicked)\n",
        "            buttons.append(button)\n",
        "\n",
        "        display(widgets.VBox(buttons), output)\n",
        "\n",
        "elif upload_option == \"Load from Google Drive\":\n",
        "    drive.mount('/content/drive')\n",
        "    root_dir = '/content/drive/MyDrive/'\n",
        "\n",
        "    audio_video_extensions = ['.mp3', '.wav', '.flac', '.aac', '.mp4', '.mkv', '.avi', '.mov']\n",
        "    files_list = []\n",
        "\n",
        "    # Рекурсивный обход всех папок в Google Drive\n",
        "    for dirpath, _, filenames in os.walk(root_dir):\n",
        "        for f in filenames:\n",
        "            if os.path.splitext(f)[1].lower() in audio_video_extensions:\n",
        "                relative_path = os.path.relpath(os.path.join(dirpath, f), root_dir)\n",
        "                files_list.append(relative_path)\n",
        "\n",
        "    if not files_list:\n",
        "        print(\"No audio or video files found in Google Drive or its subfolders.\")\n",
        "        audio_file_path = None\n",
        "    else:\n",
        "        print(\"Select a file from Google Drive (including subfolders):\")\n",
        "\n",
        "        output = widgets.Output()\n",
        "        buttons = []\n",
        "\n",
        "        def on_button_clicked(b):\n",
        "            global audio_file_path\n",
        "            with output:\n",
        "                clear_output()\n",
        "                selected_file = b.description\n",
        "                full_path = os.path.join(root_dir, selected_file)\n",
        "                if os.path.splitext(selected_file)[1].lower() in ['.mp4', '.mkv', '.avi', '.mov']:\n",
        "                    audio_file_path = convert_to_wav(full_path, \"/content/converted_audio.wav\")\n",
        "                else:\n",
        "                    audio_file_path = full_path\n",
        "                print(f\"Selected file: {audio_file_path}\")\n",
        "\n",
        "        for file in files_list:\n",
        "            button = widgets.Button(description=file)\n",
        "            button.on_click(on_button_clicked)\n",
        "            buttons.append(button)\n",
        "\n",
        "        display(widgets.VBox(buttons), output)\n",
        "\n",
        "if audio_file_path:\n",
        "    print(f\"Audio file path set to: {audio_file_path}\")\n",
        "else:\n",
        "    print(\"Audio file path not set. Please select a file.\")"
      ],
      "metadata": {
        "id": "JB2Hjo5zXgGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Run Transcription** { display-mode: \"form\" }\n",
        "selected_model = \"large\"         #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
        "selected_language = \"auto\"       #@param [\"auto\", \"ru\", \"en\", \"de\", \"fr\", \"es\", \"it\", \"uk\", \"zh\", \"ja\"]\n",
        "selected_format = \"srt\"         #@param [\"txt\", \"srt\"]\n",
        "show_text = True                #@param {type:\"boolean\"}\n",
        "\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "import whisper\n",
        "import torch\n",
        "import gc\n",
        "import datetime\n",
        "from IPython.display import display, Audio, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "if 'audio_file_path' not in globals() or audio_file_path is None:\n",
        "    print(\"Error: Audio file path not set. Please run the 'Select Audio File' cell first and choose a file.\")\n",
        "    raise SystemExit\n",
        "\n",
        "def seconds_to_srt_time(sec):\n",
        "    hours = int(sec // 3600)\n",
        "    minutes = int((sec % 3600) // 60)\n",
        "    seconds = int(sec % 60)\n",
        "    milliseconds = int((sec - int(sec)) * 1000)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}\"\n",
        "\n",
        "def extract_audio_segment(audio_path, start_time, end_time):\n",
        "    from pydub import AudioSegment\n",
        "    print(f\"Extracting segment from {start_time} to {end_time}\")\n",
        "    audio = AudioSegment.from_file(audio_path)\n",
        "    start_ms = start_time * 1000\n",
        "    end_ms = end_time * 1000\n",
        "    segment = audio[start_ms:end_ms]\n",
        "    print(\"Segment extracted\")\n",
        "    del audio\n",
        "    return segment\n",
        "\n",
        "def retranscribe_segment(audio_path, start, end, whisper_model, lang, progress_label):\n",
        "    print(\"Preparing for retranscribe...\")\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    try:\n",
        "        progress_label.value = \"Extracting audio...\"\n",
        "        print(\"Calling extract_audio_segment...\")\n",
        "        audio_segment = extract_audio_segment(audio_path, start, end)\n",
        "        temp_file = \"temp_segment.wav\"\n",
        "        print(\"Exporting audio segment to temp file...\")\n",
        "        audio_segment.export(temp_file, format=\"wav\")\n",
        "        del audio_segment\n",
        "        progress_label.value = \"Transcribing...\"\n",
        "        print(\"Starting Whisper transcription...\")\n",
        "        if lang == \"auto\":\n",
        "            result = whisper_model.transcribe(temp_file)\n",
        "        else:\n",
        "            result = whisper_model.transcribe(temp_file, language=lang)\n",
        "        print(\"Transcription completed, cleaning up...\")\n",
        "        os.remove(temp_file)\n",
        "        return result[\"text\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Error in retranscribe_segment: {str(e)}\")\n",
        "        raise\n",
        "    finally:\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "clear_output(wait=True)\n",
        "\n",
        "print(\"Starting transcription...\")\n",
        "\n",
        "if not os.path.exists(audio_file_path):\n",
        "    print(\"Audio file not found. Check the path:\", audio_file_path)\n",
        "    raise SystemExit\n",
        "\n",
        "print(f\"Loading Whisper model: {selected_model}...\")\n",
        "if 'model' not in globals() or model is None:\n",
        "    try:\n",
        "        model = whisper.load_model(selected_model)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Failed to load model: {e}\")\n",
        "        print(\"Try using a smaller model (e.g., 'medium' or 'small') or restarting the runtime.\")\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        raise SystemExit\n",
        "else:\n",
        "    print(\"Model already loaded, reusing existing instance.\")\n",
        "\n",
        "combined_text = \"\"\n",
        "combined_segments = []\n",
        "\n",
        "try:\n",
        "    print(\"Transcribing the entire file...\")\n",
        "    if selected_language == \"auto\":\n",
        "        result = model.transcribe(audio_file_path, verbose=show_text)\n",
        "    else:\n",
        "        result = model.transcribe(audio_file_path, language=selected_language, verbose=show_text)\n",
        "    combined_text = result[\"text\"]\n",
        "    combined_segments = result.get(\"segments\", [])\n",
        "    for seg in combined_segments:\n",
        "        seg[\"speaker\"] = \"Speaker\"\n",
        "except Exception as e:\n",
        "    print(f\"Error during initial transcription: {e}\")\n",
        "    if 'model' in globals():\n",
        "        del model\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    raise SystemExit\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "def create_subtitle_editor(whisper_model):\n",
        "    output = widgets.Output()\n",
        "\n",
        "    def update_srt_file():\n",
        "        with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            for i, seg in enumerate(combined_segments, start=1):\n",
        "                start_time = seconds_to_srt_time(seg[\"start\"])\n",
        "                end_time = seconds_to_srt_time(seg[\"end\"])\n",
        "                speaker = seg.get(\"speaker\", \"Unknown\")\n",
        "                text = seg[\"text\"].strip()\n",
        "                f.write(f\"{i}\\n\")\n",
        "                f.write(f\"{start_time} --> {end_time}\\n\")\n",
        "                f.write(f\"[{speaker}] {text}\\n\\n\")\n",
        "\n",
        "    def on_play_clicked(b, seg_idx):\n",
        "        with output:\n",
        "            output.clear_output()\n",
        "            audio_seg = extract_audio_segment(audio_file_path,\n",
        "                                           combined_segments[seg_idx][\"start\"],\n",
        "                                           combined_segments[seg_idx][\"end\"])\n",
        "            audio_data = audio_seg.export(format=\"wav\").read()\n",
        "            del audio_seg\n",
        "            display(Audio(audio_data, autoplay=True))\n",
        "\n",
        "    def retranscribe_segment_wrapper(seg_idx, progress_label, whisper_model):\n",
        "        print(f\"Starting retranscribe for segment {seg_idx}\")\n",
        "        try:\n",
        "            new_text = retranscribe_segment(audio_path=audio_file_path,\n",
        "                                          start=combined_segments[seg_idx][\"start\"],\n",
        "                                          end=combined_segments[seg_idx][\"end\"],\n",
        "                                          whisper_model=whisper_model,\n",
        "                                          lang=selected_language,\n",
        "                                          progress_label=progress_label)\n",
        "            combined_segments[seg_idx][\"text\"] = new_text\n",
        "            text_boxes[seg_idx].value = new_text\n",
        "            update_srt_file()\n",
        "            progress_label.value = \"Done\"\n",
        "            print(f\"Retranscribe completed for segment {seg_idx}\")\n",
        "        except Exception as e:\n",
        "            progress_label.value = f\"Error: {str(e)}\"\n",
        "            print(f\"Retranscribe failed for segment {seg_idx}: {str(e)}\")\n",
        "\n",
        "    def on_retranscribe_clicked(b, seg_idx, progress_label):\n",
        "        with output:\n",
        "            output.clear_output()\n",
        "            progress_label.value = \"Starting...\"\n",
        "            print(\"Button clicked, launching retranscribe...\")\n",
        "            retranscribe_segment_wrapper(seg_idx, progress_label, whisper_model)\n",
        "\n",
        "    def on_text_changed(change, seg_idx):\n",
        "        combined_segments[seg_idx][\"text\"] = change.new\n",
        "        update_srt_file()\n",
        "\n",
        "    text_boxes = []\n",
        "    for i, seg in enumerate(combined_segments):\n",
        "        start_time = seconds_to_srt_time(seg[\"start\"])\n",
        "        end_time = seconds_to_srt_time(seg[\"end\"])\n",
        "        time_label = widgets.Label(value=f'{start_time} --> {end_time}',\n",
        "                                 layout={'width': '250px'})\n",
        "\n",
        "        text_box = widgets.Textarea(\n",
        "            value=seg[\"text\"],\n",
        "            layout={'width': '500px'}\n",
        "        )\n",
        "        text_box.observe(lambda change, idx=i: on_text_changed(change, idx), names='value')\n",
        "\n",
        "        play_button = widgets.Button(description=\"Play\")\n",
        "        play_button.on_click(lambda b, idx=i: on_play_clicked(b, idx))\n",
        "\n",
        "        retranscribe_button = widgets.Button(description=\"Retranscribe\")\n",
        "        progress_label = widgets.Label(value=\"\", layout={'width': '150px'})\n",
        "\n",
        "        retranscribe_button.on_click(lambda b, idx=i, pl=progress_label: on_retranscribe_clicked(b, idx, pl))\n",
        "\n",
        "        hbox = widgets.HBox([time_label, text_box, play_button, retranscribe_button, progress_label])\n",
        "        text_boxes.append(text_box)\n",
        "        display(hbox)\n",
        "\n",
        "    display(output)\n",
        "\n",
        "if selected_format == \"txt\":\n",
        "    output_file_path = f\"transcription_{timestamp}.txt\"\n",
        "    with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for seg in combined_segments:\n",
        "            speaker = seg.get(\"speaker\", \"Unknown\")\n",
        "            text = seg[\"text\"].strip()\n",
        "            f.write(f\"[{speaker}] {text}\\n\")\n",
        "    print(f\"Transcription completed. Result in file {output_file_path}\")\n",
        "\n",
        "elif selected_format == \"srt\":\n",
        "    output_file_path = f\"transcription_{timestamp}.srt\"\n",
        "    with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, seg in enumerate(combined_segments, start=1):\n",
        "            start_time = seconds_to_srt_time(seg[\"start\"])\n",
        "            end_time = seconds_to_srt_time(seg[\"end\"])\n",
        "            speaker = seg.get(\"speaker\", \"Unknown\")\n",
        "            text = seg[\"text\"].strip()\n",
        "            f.write(f\"{i}\\n\")\n",
        "            f.write(f\"{start_time} --> {end_time}\\n\")\n",
        "            f.write(f\"[{speaker}] {text}\\n\\n\")\n",
        "    print(f\"Transcription completed. Result in file {output_file_path}\")\n",
        "\n",
        "    print(\"\\nInteractive Subtitle Editor:\")\n",
        "    create_subtitle_editor(model)\n",
        "\n",
        "else:\n",
        "    print(\"Unknown format. Check the selected format settings.\")\n",
        "\n",
        "print(\"Cleaning up memory at the end...\")\n",
        "if 'model' in globals():\n",
        "    del model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "r6u7HhzpX3s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Download** { display-mode: \"form\" }\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "if \"output_file_path\" in globals() and output_file_path and os.path.exists(output_file_path):\n",
        "    files.download(output_file_path)\n",
        "    print(f\"File {output_file_path} download to your computer has started.\")\n",
        "else:\n",
        "    print(\"Result file not found. Please complete Step 3 first.\")\n"
      ],
      "metadata": {
        "id": "rUyrzg9aZlA0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}